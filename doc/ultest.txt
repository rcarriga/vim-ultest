*ultest.txt*
                                                         *vim-ultest* *ultest*

==============================================================================
CONTENTS                                                     *ultest-contents*
  1. Introduction........................................|ultest-introduction|
  2. Configuration.............................................|ultest-config|
  3. Commands................................................|ultest-commands|
  4. Functions..............................................|ultest-functions|
  5. Highlights............................................|ultest-highlights|
  6. Mappings................................................|ultest-mappings|
  7. Debugging..............................................|ultest-debugging|

==============================================================================
INTRODUCTION                                             *ultest-introduction*


The ultimate testing plugin for Vim/NeoVim

Running tests should be as quick and painless as possible.
[vim-test](https://github.com/janko/vim-test) is a very powerful and extensive
testing plugin, but it can be cumbersome to configure and lacks some features
to make it feel like an integrated piece of your editor. Rather than replacing
vim-test altogether, vim-ultest makes it even better while maintaining the
ability to use your existing configuration. If you're already using vim-test
then switching to vim-ultest is as easy as installing and... well, that's
pretty much it.

The goal behind vim-ultest is to make running tests as seamless as possible.

  * Tests are run individually so that any errors can be addressed
    individually.
  * Tests are run in seperate threads (not just asynchronously on the same
    thread) so your Vim session will never be blocked.
  * When tests are complete, results can be viewed immediately or on command.
  * Utilise the existing power of vim-test by extending upon it.

==============================================================================
CONFIGURATION                                                  *ultest-config*

                                                        *g:ultest_max_threads*
Number of workers that are used for running tests. (default: 2)

                                                      *g:ultest_output_on_run*
Show failed outputs when completed run. (default: 1)

                                                     *g:ultest_output_on_line*
Show failed outputs when cursor is on first line of test.

This relies on the 'updatetime' setting which by default is 4 seconds. A
longer 'updatetime' will mean the window takes longer to show automatically
but a shorter time means (Neo)Vim will write to disk much more often which can
degrade SSDs over time and cause slowdowns on HDDs.

Due to how Vim handles terminal popups, this is disabled by default as it can
be annoying. (default: has("nvim"))

                                                              *g:ultest_icons*
Use unicode icons for results signs/virtual text. (default: 1)

                                                        *g:ultest_output_rows*
Number of rows for terminal size where tests are run (default: 0) Set to zero
to not instruct runner on size of terminal. Note: It is up to the test runner
to respect these bounds

                                                        *g:ultest_output_cols*
Number of columns for terminal size where tests are run (default: 0) Set to
zero to not instruct runner on size of terminal. Note: It is up to the test
runner to respect these bounds

                                                       *g:ultest_show_in_file*
Enable sign/virtual text processor for tests. (default: 1)

                                                       *g:ultest_virtual_text*
Use virtual text (if available) instead of signs to show test results in file.
(default: 0)

                                                          *g:ultest_pass_sign*
Sign for passing tests. (default: g:ultest_icons ? "●" : "O")

                                                          *g:ultest_fail_sign*
Sign for failing tests. (default: g:ultest_icons ? "●" : "X")

                                                       *g:ultest_running_sign*
Sign for running tests (string) (default: g:ultest_icons ? "●" : "X")

                                                          *g:ultest_pass_text*
Virtual text for passing tests (string) (default: g:ultest_icons?
"●":"Passing")

                                                          *g:ultest_fail_text*
Virtual text for failing tests (string) (default: g:ultest_icons?
"●":"Failing")

                                                       *g:ultest_running_text*
Virtual text for passing tests (string) (default: g:ultest_icons?
"●":"Running")

                                                      *g:ultest_summary_width*
Width of the summary window (default: 50)

                                                       *g:ultest_attach_width*
Width of the attach window Some test runners don't output anyting until
finished (e.g. Jest) so the attach window can't figure out a good width. Use
this to hardcode a size. (default: 0)

                                                  *g:ultest_custom_processors*
Custom list of receivers for test events. This is experimental and could
change! Receivers are dictionaries with any of the following keys:

'new': A function which takes a new test which has been discovered.

'move': A function which takes a test which has been moved.

'replace': A function which takes a test which has previously been cleared but
has been replaced.

'start': A function which takes a test which has been run.

'exit': A function which takes a test result once it has completed.

'clear': A function which takes a test which has been removed for some reason.


                                                    *g:ultest_custom_patterns*
Custom patterns for identifying tests. This dictionary should use the keys in
the form '<language>' or '<language>#<runner>'. The values should be a
dictionary with the following keys:

'test': A list a python-style regex patterns that can each indentify tests in
a line of code

'namepsace': A list of python-style regex patterns that can idenitfy test
namespaces (e.g. Classes). This feature is currently unsupporte but will be in
the future.

If you find a missing language that requires you to set this value,
considering onpening an issue/PR to make it available to others.

                                                   *g:ultest_summary_mappings*
Key mappings for the summary window (dict) Possible values:

'run': (default "r") Runs the test currently selected or whole file if file
name is selected.

'jumpto': (default "<CR>") Jump to currently selected test in its file.

'output': (default "o") Open the output to the current test if failed.

'attach': (default "a") Attach to the running process of the current test.

'stop': (default "s") Stop the running process of the current test.

'next_fail': (default "<S-j>") Jump down to the next fail.

'prev_fail': (default "<S-k>") Jump up to the next fail.

The summary window also defines folds for each test file so they can be hidden
as desired using the regular fold mappings.

==============================================================================
COMMANDS                                                     *ultest-commands*

:Ultest                                                              *:Ultest*
  Run all tests in the current file

:UltestNearest                                                *:UltestNearest*
  Run nearest test in the current file

:UltestDebugNearest                                      *:UltestDebugNearest*
  Debug the nearest test with nvim-dap

:UltestOutput                                                  *:UltestOutput*
  Show the output of the nearest test in the current file

:UltestAttach                                                  *:UltestAttach*
  Attach to the running process of a test to be able to send input and read
  output as it runs. This is useful for debugging

:UltestStop                                                      *:UltestStop*
  Stop all running jobs for the current file

:UltestStopNearest                                        *:UltestStopNearest*
  Stop any running jobs and results for the nearest test

:UltestSummary                                                *:UltestSummary*
  Toggle the summary window between open and closed

:UltestSummaryOpen                                        *:UltestSummaryOpen*
  Open the summary window

:UltestSummaryClose                                      *:UltestSummaryClose*
  Close the summary window

==============================================================================
FUNCTIONS                                                   *ultest-functions*

ultest#status([file])                                        *ultest#status()*
  Get the status of a file. If the [file] argument is not given, the current
  buffer will be used. Full paths are expected for [file].

  The return value is a dict with the following keys:

  'tests': Number of tests found

  'passed': Number of tests passed

  'failed': Number of tests failed

  'running': Number of tests running

ultest#is_test_file([file])                            *ultest#is_test_file()*
  Check if a file has tests detected within it. N.B. This can return false if
  a file has not been processed yet. You can use the 'User
  UltestPositionsUpdate' autocommand to detect when a file has been processed.

  If the [file] argument is not given, the current buffer will be used. Full
  paths are expected for [file].

==============================================================================
HIGHLIGHTS                                                 *ultest-highlights*


Define the following highlight groups to override their values by copying
these commands and changing their colours/attributes.

hi UltestPass ctermfg=Green guifg=#96F291

hi UltestFail ctermfg=Red guifg=#F70067

hi UltestRunning ctermfg=Yellow guifg=#FFEC63

hi UltestBorder ctermfg=Red guifg=#F70067

hi UltestInfo ctermfg=cyan guifg=#00F1F5 cterm=bold gui=bold

==============================================================================
MAPPINGS                                                     *ultest-mappings*


<Plug>(ultest-next-fail)         Jump to next failed test.

<Plug>(ultest-prev-fail)         Jump to previous failed test.

<Plug>(ultest-run-file)          Run all tests in a file.

<Plug>(ultest-run-nearest)       Run test closest to the cursor.

<Plug>(ultest-summary-toggle)    Toggle the summary window between open and
closed

<Plug>(ultest-summary-jump)      Jump to the summary window (opening if it
isn't already)

<Plug>(ultest-output-show)       Show error output of the nearest test. (Will
jump to popup window in Vim)

<Plug>(ultest-output-jump)       Show error output of the nearest test. (Same
behabviour as <Plug>(ultest-output-show) in Vim)

<Plug>(ultest-attach)    Attach to the nearest test's running process.

<Plug>(ultest-stop-file)         Stop all running jobs for current file

<Plug>(ultest-stop-nearest)      Stop any running jobs for nearest test

<Plug>(ultest-debug-nearest)      Debug the nearest test with nvim-dap

==============================================================================
DEBUGGING                                                   *ultest-debugging*


vim-ultest supports debugging through nvim-dap. Due to how debugging
configurations can vary greatly between users and projects, some configuration
is required for test debugging to work.

You must provide a way to build a suitable nvim-dap confiuration to run a
test, given the original command for the test. The command is given in the
form of a list of strings. The returned table should contain a 'dap' entry
which will be provided to nvim-dap's 'run' function.

For example with a python test using the adapter defined in nvim-dap-python:
>
  function(cmd)
    -- The command can start with python command directly or an env manager
    local non_modules = {'python', 'pipenv', 'poetry'}
    -- Index of the python module to run the test.
    local module
    if vim.tbl_contains(non_modules, cmd[1]) then
      module = cmd[3]
    else
      module = cmd[1]
    end
    -- Remaining elements are arguments to the module
    local args = vim.list_slice(cmd, module_index + 1)
    return {
      dap = {
        type = 'python',
        request = 'launch',
        module = module,
        args = args
      }
    }
  end,
<
This will separate out the module name and arguments to provide to the
nvim-dap-python adapter.

To provide this to vim-ultest, call the setup function, providing a table with
a 'builders' entry, with your language mapped to the builder. If you require
multiple runners, the key can be in the form of '<language>#<runner>'
(Example: 'python#pytest')
>
  require("ultest").setup({
    builders = {
      ['python#pytest'] = function (cmd)
        ...
      end
    }
  })
<

Some adapters don't provide an exit code when running tests, such as
vscode-go. This causes vim-ultest to never receive a result. To work around
this, you can provide a 'parse_result' entry in the returned table of your
config builder function which will receive the output of the program as a list
of lines. You can then return an exit code for the test. For example with
vscode-go and gotest, the final line will state 'FAIL' on a failed test.
>
  ["go#gotest"] = function(cmd)
    local args = {}
    for i = 3, #cmd - 1, 1 do
      local arg = cmd[i]
      if vim.startswith(arg, "-") then
        -- Delve requires test flags be prefix with 'test.'
        arg = "-test." .. string.sub(arg, 2)
      end
      args[#args + 1] = arg
    end
    return {
      dap = {
        type = "go",
        request = "launch",
        mode = "test",
        program = "${workspaceFolder}",
        dlvToolPath = vim.fn.exepath("dlv"),
        args = args
      },
      parse_result = function(lines)
        return lines[#lines] == "FAIL" and 1 or 0
      end
    }
  end
<


vim:tw=78:ts=8:ft=help:norl:
