*ultest.txt*
                                                         *vim-ultest* *ultest*

==============================================================================
CONTENTS                                                     *ultest-contents*
  1. Introduction........................................|ultest-introduction|
  2. Configuration.............................................|ultest-config|
  3. Commands................................................|ultest-commands|
  4. Functions..............................................|ultest-functions|
  5. Highlights............................................|ultest-highlights|
  6. Mappings................................................|ultest-mappings|
  7. Debugging..............................................|ultest-debugging|

==============================================================================
INTRODUCTION                                             *ultest-introduction*


The ultimate testing plugin for Vim/NeoVim

Running tests should be as quick and painless as possible.
[vim-test](https://github.com/janko/vim-test) is a very powerful and extensive
testing plugin, but it can be cumbersome to configure and lacks some features
to make it feel like an integrated piece of your editor. Rather than replacing
vim-test altogether, vim-ultest makes it even better while maintaining the
ability to use your existing configuration. If you're already using vim-test
then switching to vim-ultest is as easy as installing and... well, that's
pretty much it.

The goal behind vim-ultest is to make running tests as seamless as possible.

  * Tests are displayed individually so that any errors can be addressed
    individually.
  * Tests are run in seperate threads (not just asynchronously on the same
    thread) so your Vim session will never be blocked.
  * When tests are complete, results can be viewed immediately or on command.
  * Utilise the existing power of vim-test by extending upon it.

==============================================================================
CONFIGURATION                                                  *ultest-config*

                                                        *g:ultest_max_threads*
Number of workers that are used for running tests. (default: 2)

                                                                *g:ultest_env*

Custom environment variables for test processes in a dictionary. (default:
v:null)

                                                      *g:ultest_output_on_run*
Show failed outputs when completed run. (default: 1)

                                                     *g:ultest_output_on_line*
Show failed outputs when cursor is on first line of test/namespace.

This relies on the 'updatetime' setting which by default is 4 seconds. A
longer 'updatetime' will mean the window takes longer to show automatically
but a shorter time means (Neo)Vim will write to disk much more often which can
degrade SSDs over time and cause slowdowns on HDDs.

Due to how Vim handles terminal popups, this is disabled by default as it can
be annoying. (default: has("nvim"))

                                                              *g:ultest_icons*
Use unicode icons (default: 1)

                                                        *g:ultest_output_rows*
Number of rows for terminal size where tests are run (default: 0) Set to zero
to not instruct runner on size of terminal. Note: It is up to the test runner
to respect these bounds

                                                        *g:ultest_output_cols*
Number of columns for terminal size where tests are run (default: 0) Set to
zero to not instruct runner on size of terminal. Note: It is up to the test
runner to respect these bounds

                                                       *g:ultest_show_in_file*
Enable sign/virtual text processor for tests. (default: 1)

                                                       *g:ultest_virtual_text*
Use virtual text (if available) instead of signs to show test results in file.
(default: 0)

                                                          *g:ultest_pass_sign*
Sign for passing tests. (default: g:ultest_icons ? "" : "O")

                                                          *g:ultest_fail_sign*
Sign for failing tests. (default: g:ultest_icons ? "" : "X")

                                                       *g:ultest_running_sign*
Sign for running tests (string) (default: g:ultest_icons ? "" : ">")

                                                       *g:ultest_not_run_sign*
Sign for tests not yet run (string) (default: g:ultest_icons ? "" : "~")

                                                          *g:ultest_pass_text*
Virtual text for passing tests (string) (default: g:ultest_icons?
"●":"Passing")

                                                          *g:ultest_fail_text*
Virtual text for failing tests (string) (default: g:ultest_icons?
"●":"Failing")

                                                       *g:ultest_running_text*
Virtual text for passing tests (string) (default: g:ultest_icons?
"●":"Running")

                                                      *g:ultest_summary_width*
Width of the summary window (default: 50)

                                                            *g:ultest_pre_run*
A function name to call before running any tests in a file. Receives the
relative file path as an argument.

                                                       *g:ultest_attach_width*
Width of the attach window Some test runners don't output anyting until
finished (e.g. Jest) so the attach window can't figure out a good width. Use
this to hardcode a size. (default: 0)

                                                  *g:ultest_custom_processors*
Custom list of receivers for position events. This is experimental and could
change! Receivers are dictionaries with any of the following keys:

'new': A function which takes a new position which has been discovered.

'move': A function which takes a position which has been moved.

'replace': A function which takes a position which has previously been cleared
but has been replaced.

'start': A function which takes a position which has been run.

'exit': A function which takes a position result once it has completed.

'clear': A function which takes a position which has been removed for some
reason.

Positions can be either a file, namespace or test, distinguished with a 'type'
key.


                                                    *g:ultest_custom_patterns*
Custom patterns for identifying positions. This dictionary should use the keys
in the form '<language>' or '<language>#<runner>'. The values should be a
dictionary with the following keys:

'test': A list a python-style regex patterns that can each indentify tests in
a line of code

'namepsace': A list of python-style regex patterns that can idenitfy test
namespaces (e.g. Classes).

If you find a missing language that requires you to set this value,
considering onpening an issue/PR to make it available to others.

                                                   *g:ultest_summary_mappings*
Key mappings for the summary window (dict) Possible values:

'run': (default "r") Runs the test currently selected or whole file if file
name is selected.

'jumpto': (default "<CR>") Jump to currently selected test in its file.

'output': (default "o") Open the output to the current test if failed.

'attach': (default "a") Attach to the running process of the current test.

'stop': (default "s") Stop the running process of the current test.

'next_fail': (default "<S-j>") Jump down to the next fail.

'prev_fail': (default "<S-k>") Jump up to the next fail.

The summary window also defines folds for each files and namespaces so they
can be hidden as desired using the regular fold mappings.

==============================================================================
COMMANDS                                                     *ultest-commands*

:Ultest                                                              *:Ultest*
  Run all tests in the current file Some runners can be run as a single
  command if the output can be parsed to gain results. Otherwise, each test is
  run as a single command.

  Running as a single command can significanly improve performance, so if your
  runner is not yet supported please open an issue with sample output! Check
  the repo wiki for an updated list of runners.

:UltestNearest                                                *:UltestNearest*
  Run nearest position in the current file If no position is found it will
  attempt to run the entire file

:UltestDebug                                                    *:UltestDebug*
  Debug the current file with nvim-dap

:UltestDebugNearest                                      *:UltestDebugNearest*
  Debug the nearest position with nvim-dap

:UltestOutput                                                  *:UltestOutput*
  Show the output of the nearest position in the current file

:UltestAttach                                                  *:UltestAttach*
  Attach to the running process of a position to be able to send input and
  read output as it runs. This is useful for debugging

:UltestStop                                                      *:UltestStop*
  Stop all running jobs for the current file

:UltestStopNearest                                        *:UltestStopNearest*
  Stop any running jobs and results for the nearest position

:UltestSummary                                                *:UltestSummary*
  Toggle the summary window between open and closed

:UltestSummaryOpen                                        *:UltestSummaryOpen*
  Open the summary window

:UltestSummaryClose                                      *:UltestSummaryClose*
  Close the summary window

:UltestClear                                                    *:UltestClear*
  Clear results from the current file

==============================================================================
FUNCTIONS                                                   *ultest-functions*

ultest#status([file])                                        *ultest#status()*
  Get the status of a file. If the [file] argument is not given, the current
  buffer will be used. Full paths are expected for [file].

  The return value is a dict with the following keys:

  'tests': Number of tests found

  'passed': Number of tests passed

  'failed': Number of tests failed

  'running': Number of tests running

ultest#is_test_file([file])                            *ultest#is_test_file()*
  Check if a file has tests detected within it. N.B. This can return false if
  a file has not been processed yet. You can use the 'User
  UltestPositionsUpdate' autocommand to detect when a file has been processed.

  If the [file] argument is not given, the current buffer will be used. Full
  paths are expected for [file].

==============================================================================
HIGHLIGHTS                                                 *ultest-highlights*


Define the following highlight groups to override their values by copying
these commands and changing their colours/attributes.

hi UltestPass ctermfg=Green guifg=#96F291

hi UltestFail ctermfg=Red guifg=#F70067

hi UltestRunning ctermfg=Yellow guifg=#FFEC63

hi UltestBorder ctermfg=Red guifg=#F70067

hi UltestSummaryInfo ctermfg=cyan guifg=#00F1F5 gui=bold cterm=bold

hi link UltestSummaryFile UltestSummaryInfo

hi link UltestSummaryNamespace UltestSummaryInfo

==============================================================================
MAPPINGS                                                     *ultest-mappings*


<Plug>(ultest-next-fail)         Jump to next failed test.

<Plug>(ultest-prev-fail)         Jump to previous failed test.

<Plug>(ultest-run-file)          Run all tests in a file.

<Plug>(ultest-run-nearest)       Run test closest to the cursor.

<Plug>(ultest-summary-toggle)    Toggle the summary window between open and
closed

<Plug>(ultest-summary-jump)      Jump to the summary window (opening if it
isn't already)

<Plug>(ultest-output-show)       Show error output of the nearest test. (Will
jump to popup window in Vim)

<Plug>(ultest-output-jump)       Show error output of the nearest test. (Same
behabviour as <Plug>(ultest-output-show) in Vim)

<Plug>(ultest-attach)    Attach to the nearest test's running process.

<Plug>(ultest-stop-file)         Stop all running jobs for current file

<Plug>(ultest-stop-nearest)      Stop any running jobs for nearest test

<Plug>(ultest-debug)      Debug the current file with nvim-dap

<Plug>(ultest-debug-nearest)      Debug the nearest test with nvim-dap

==============================================================================
DEBUGGING                                                   *ultest-debugging*


vim-ultest supports debugging through nvim-dap. Due to how debugging
configurations can vary greatly between users and projects, some configuration
is required for test debugging to work.

You must provide a way to build a suitable nvim-dap confiuration to run a
test, given the original command for the test. The command is given in the
form of a list of strings. The returned table should contain a 'dap' entry
which will be provided to nvim-dap's 'run' function.

For example with a python test using the adapter defined in nvim-dap-python:
>
  function(cmd)
    -- The command can start with python command directly or an env manager
    local non_modules = {'python', 'pipenv', 'poetry'}
    -- Index of the python module to run the test.
    local module
    if vim.tbl_contains(non_modules, cmd[1]) then
      module = cmd[3]
    else
      module = cmd[1]
    end
    -- Remaining elements are arguments to the module
    local args = vim.list_slice(cmd, module_index + 1)
    return {
      dap = {
        type = 'python',
        request = 'launch',
        module = module,
        args = args
      }
    }
  end,
<
This will separate out the module name and arguments to provide to the
nvim-dap-python adapter.

To provide this to vim-ultest, call the setup function, providing a table with
a 'builders' entry, with your language mapped to the builder. If you require
multiple runners, the key can be in the form of '<language>#<runner>'
(Example: 'python#pytest')
>
  require("ultest").setup({
    builders = {
      ['python#pytest'] = function (cmd)
        ...
      end
    }
  })
<

Some adapters don't provide an exit code when running tests, such as
vscode-go. This causes vim-ultest to never receive a result. To work around
this, you can provide a 'parse_result' entry in the returned table of your
config builder function which will receive the output of the program as a list
of lines. You can then return an exit code for the test. For example with
vscode-go and gotest, the final line will state 'FAIL' on a failed test.
>
  ["go#gotest"] = function(cmd)
    local args = {}
    for i = 3, #cmd - 1, 1 do
      local arg = cmd[i]
      if vim.startswith(arg, "-") then
        -- Delve requires test flags be prefix with 'test.'
        arg = "-test." .. string.sub(arg, 2)
      end
      args[#args + 1] = arg
    end
    return {
      dap = {
        type = "go",
        request = "launch",
        mode = "test",
        program = "${workspaceFolder}",
        dlvToolPath = vim.fn.exepath("dlv"),
        args = args
      },
      parse_result = function(lines)
        return lines[#lines] == "FAIL" and 1 or 0
      end
    }
  end
<


vim:tw=78:ts=8:ft=help:norl:
